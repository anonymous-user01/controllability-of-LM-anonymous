{"task": "rl", "behavior_model": "gpt2_small", "dataset": "topic-0", "rl_lr": 0.0005, "batch_size": 256, "num_epoch": 20, "decoding": "stochastic", "prefix_len": 2, "gen_len": 15, "dropout": "quantile", "dropout_rate": 0.9}