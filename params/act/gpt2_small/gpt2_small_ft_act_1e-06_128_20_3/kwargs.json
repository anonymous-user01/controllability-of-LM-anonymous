{"model": "gpt2_small", "task": "ft", "dataset": "act", "lr": 1e-06, "batch_size": 128, "num_epoch": 20, "num_patience": 3}